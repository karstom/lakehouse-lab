{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostgreSQL Analytics with Lakehouse Lab\n",
    "\n",
    "This notebook demonstrates PostgreSQL integration for analytics workloads, combining SQL with Python data science tools.\n",
    "\n",
    "## What's Covered\n",
    "\n",
    "- **PostgreSQL**: Relational database integration\n",
    "- **DuckDB**: High-performance analytics on PostgreSQL data\n",
    "- **Cross-system queries**: PostgreSQL + S3 data federation\n",
    "- **Data visualization**: Charts and dashboards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import duckdb\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ PostgreSQL Analytics Environment Ready!\")\n",
    "print(f\"üìä DuckDB version: {duckdb.__version__}\")\n",
    "print(f\"üêò psycopg2 version: {psycopg2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# PostgreSQL connection with environment variables\npg_host = 'postgres'\npg_user = os.environ.get('POSTGRES_USER', 'postgres')\npg_password = os.environ.get('POSTGRES_PASSWORD', 'postgres')\npg_database = os.environ.get('POSTGRES_DB', 'lakehouse')\npg_port = 5432\n\n# Create SQLAlchemy engine\npg_engine = create_engine(\n    f'postgresql://{pg_user}:{pg_password}@{pg_host}:{pg_port}/{pg_database}'\n)\n\n# Test connection\ntry:\n    with pg_engine.connect() as conn:\n        result = conn.execute(\"SELECT version()\")\n        version = result.fetchone()[0]\n        print(f\"‚úÖ Connected to PostgreSQL: {version.split(',')[0]}\")\nexcept Exception as e:\n    print(f\"‚ùå PostgreSQL connection failed: {e}\")\n    print(\"Make sure PostgreSQL service is running and accessible\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample PostgreSQL Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create sample tables in PostgreSQL\ntry:\n    with pg_engine.connect() as conn:\n        with conn.begin():\n            # Create customers table\n            conn.execute(\"\"\"\n                DROP TABLE IF EXISTS orders CASCADE;\n                DROP TABLE IF EXISTS customers CASCADE;\n                \n                CREATE TABLE customers (\n                    customer_id SERIAL PRIMARY KEY,\n                    customer_name VARCHAR(100) NOT NULL,\n                    email VARCHAR(100) UNIQUE,\n                    city VARCHAR(50),\n                    country VARCHAR(50),\n                    signup_date DATE DEFAULT CURRENT_DATE\n                );\n            \"\"\")\n            \n            # Create orders table\n            conn.execute(\"\"\"\n                CREATE TABLE orders (\n                    order_id SERIAL PRIMARY KEY,\n                    customer_id INTEGER REFERENCES customers(customer_id),\n                    order_date DATE DEFAULT CURRENT_DATE,\n                    product_name VARCHAR(100),\n                    quantity INTEGER,\n                    unit_price DECIMAL(10,2),\n                    total_amount DECIMAL(10,2)\n                );\n            \"\"\")\n            \n            # Insert sample customers\n            conn.execute(\"\"\"\n                INSERT INTO customers (customer_name, email, city, country) VALUES\n                ('Alice Johnson', 'alice@example.com', 'New York', 'USA'),\n                ('Bob Smith', 'bob@example.com', 'London', 'UK'),\n                ('Carol Brown', 'carol@example.com', 'Toronto', 'Canada'),\n                ('David Wilson', 'david@example.com', 'Sydney', 'Australia'),\n                ('Eva Martinez', 'eva@example.com', 'Madrid', 'Spain');\n            \"\"\")\n            \n            # Insert sample orders\n            conn.execute(\"\"\"\n                INSERT INTO orders (customer_id, product_name, quantity, unit_price, total_amount) VALUES\n                (1, 'Laptop', 1, 999.99, 999.99),\n                (1, 'Mouse', 2, 25.50, 51.00),\n                (2, 'Keyboard', 1, 79.99, 79.99),\n                (2, 'Monitor', 1, 299.99, 299.99),\n                (3, 'Headphones', 1, 149.99, 149.99),\n                (4, 'Tablet', 1, 399.99, 399.99),\n                (5, 'Phone', 1, 699.99, 699.99);\n            \"\"\")\n            \n    print(\"‚úÖ Sample PostgreSQL data created successfully\")\nexcept Exception as e:\n    print(f\"‚ùå Failed to create sample data: {e}\")\n    print(f\"Error details: {str(e)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PostgreSQL Analytics Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query PostgreSQL data with pandas\n",
    "customers_df = pd.read_sql(\"\"\"\n",
    "    SELECT * FROM customers ORDER BY customer_id\n",
    "\"\"\", pg_engine)\n",
    "\n",
    "print(\"Customers in PostgreSQL:\")\n",
    "display(customers_df)\n",
    "\n",
    "orders_df = pd.read_sql(\"\"\"\n",
    "    SELECT * FROM orders ORDER BY order_id\n",
    "\"\"\", pg_engine)\n",
    "\n",
    "print(\"\\nOrders in PostgreSQL:\")\n",
    "display(orders_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced analytics query\n",
    "customer_analytics = pd.read_sql(\"\"\"\n",
    "    SELECT \n",
    "        c.country,\n",
    "        COUNT(DISTINCT c.customer_id) as customer_count,\n",
    "        COUNT(o.order_id) as total_orders,\n",
    "        SUM(o.total_amount) as total_revenue,\n",
    "        AVG(o.total_amount) as avg_order_value\n",
    "    FROM customers c\n",
    "    LEFT JOIN orders o ON c.customer_id = o.customer_id\n",
    "    GROUP BY c.country\n",
    "    ORDER BY total_revenue DESC\n",
    "\"\"\", pg_engine)\n",
    "\n",
    "print(\"Customer Analytics by Country:\")\n",
    "display(customer_analytics)\n",
    "\n",
    "# Visualize the data\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Revenue by country\n",
    "ax1.bar(customer_analytics['country'], customer_analytics['total_revenue'])\n",
    "ax1.set_title('Total Revenue by Country')\n",
    "ax1.set_xlabel('Country')\n",
    "ax1.set_ylabel('Revenue ($)')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Average order value by country\n",
    "ax2.bar(customer_analytics['country'], customer_analytics['avg_order_value'])\n",
    "ax2.set_title('Average Order Value by Country')\n",
    "ax2.set_xlabel('Country')\n",
    "ax2.set_ylabel('Avg Order Value ($)')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DuckDB + PostgreSQL Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DuckDB and configure S3\n",
    "duck_conn = duckdb.connect()\n",
    "\n",
    "# Configure S3 access with environment variables\n",
    "minio_user = os.environ.get('MINIO_ROOT_USER', 'minio')\n",
    "minio_password = os.environ.get('MINIO_ROOT_PASSWORD', 'minio123')\n",
    "\n",
    "duck_conn.execute(\"\"\"\n",
    "    INSTALL httpfs;\n",
    "    LOAD httpfs;\n",
    "    SET s3_endpoint='minio:9000';\n",
    "    SET s3_use_ssl=false;\n",
    "    SET s3_url_style='path';\n",
    "\"\"\")\n",
    "\n",
    "duck_conn.execute(f\"SET s3_access_key_id='{minio_user}';\")\n",
    "duck_conn.execute(f\"SET s3_secret_access_key='{minio_password}';\")\n",
    "\n",
    "print(\"‚úÖ DuckDB configured for S3 access\")\n",
    "\n",
    "# Install and configure PostgreSQL extension\n",
    "try:\n",
    "    duck_conn.execute(\"INSTALL postgres;\")\n",
    "    duck_conn.execute(\"LOAD postgres;\")\n",
    "    print(\"‚úÖ PostgreSQL extension loaded in DuckDB\")\nexcept Exception as e:\n",
    "    print(f\"PostgreSQL extension not available: {e}\")\n",
    "    print(\"Will demonstrate with pandas DataFrame instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate cross-system analytics\n",
    "# Load PostgreSQL data into DuckDB for analysis\n",
    "duck_conn.register('pg_customers', customers_df)\n",
    "duck_conn.register('pg_orders', orders_df)\n",
    "\n",
    "# Query S3 data and join with PostgreSQL data\n",
    "cross_system_analysis = duck_conn.execute(\"\"\"\n",
    "    WITH s3_orders AS (\n",
    "        SELECT \n",
    "            customer_name,\n",
    "            product_category,\n",
    "            total_amount as s3_amount\n",
    "        FROM read_csv_auto('s3://lakehouse/raw-data/sample_orders.csv')\n",
    "    ),\n",
    "    pg_summary AS (\n",
    "        SELECT \n",
    "            c.customer_name,\n",
    "            c.country,\n",
    "            SUM(o.total_amount) as pg_amount\n",
    "        FROM pg_customers c\n",
    "        LEFT JOIN pg_orders o ON c.customer_id = o.customer_id\n",
    "        GROUP BY c.customer_name, c.country\n",
    "    )\n",
    "    SELECT \n",
    "        pg.customer_name,\n",
    "        pg.country,\n",
    "        pg.pg_amount,\n",
    "        COUNT(s3.s3_amount) as s3_order_count,\n",
    "        SUM(s3.s3_amount) as s3_total\n",
    "    FROM pg_summary pg\n",
    "    LEFT JOIN s3_orders s3 ON pg.customer_name = s3.customer_name\n",
    "    GROUP BY pg.customer_name, pg.country, pg.pg_amount\n",
    "    ORDER BY pg.pg_amount DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Cross-System Analytics (PostgreSQL + S3):\")\n",
    "display(cross_system_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced PostgreSQL Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based analysis\n",
    "time_analysis = pd.read_sql(\"\"\"\n",
    "    SELECT \n",
    "        DATE_TRUNC('day', order_date) as order_day,\n",
    "        COUNT(*) as daily_orders,\n",
    "        SUM(total_amount) as daily_revenue,\n",
    "        AVG(total_amount) as avg_order_value\n",
    "    FROM orders\n",
    "    GROUP BY DATE_TRUNC('day', order_date)\n",
    "    ORDER BY order_day\n",
    "\"\"\", pg_engine)\n",
    "\n",
    "print(\"Daily Analytics:\")\n",
    "display(time_analysis)\n",
    "\n",
    "# Product performance\n",
    "product_analysis = pd.read_sql(\"\"\"\n",
    "    SELECT \n",
    "        product_name,\n",
    "        COUNT(*) as order_count,\n",
    "        SUM(quantity) as total_quantity,\n",
    "        SUM(total_amount) as total_revenue,\n",
    "        AVG(unit_price) as avg_price\n",
    "    FROM orders\n",
    "    GROUP BY product_name\n",
    "    ORDER BY total_revenue DESC\n",
    "\"\"\", pg_engine)\n",
    "\n",
    "print(\"\\nProduct Performance:\")\n",
    "display(product_analysis)\n",
    "\n",
    "# Visualize product performance\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.bar(product_analysis['product_name'], product_analysis['total_revenue'])\n",
    "plt.title('Revenue by Product')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Revenue ($)')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.bar(product_analysis['product_name'], product_analysis['total_quantity'])\n",
    "plt.title('Quantity Sold by Product')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Quantity')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.bar(product_analysis['product_name'], product_analysis['avg_price'])\n",
    "plt.title('Average Price by Product')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Price ($)')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sizes = product_analysis['total_revenue']\n",
    "plt.pie(sizes, labels=product_analysis['product_name'], autopct='%1.1f%%')\n",
    "plt.title('Revenue Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Explore more PostgreSQL features**: Window functions, CTEs, advanced joins\n",
    "2. **Scale with DuckDB**: Use DuckDB for heavy analytics on PostgreSQL exports\n",
    "3. **Real-time dashboards**: Connect Superset to PostgreSQL for live dashboards\n",
    "4. **Data pipelines**: Use Airflow to orchestrate PostgreSQL ‚Üí S3 ‚Üí DuckDB workflows\n",
    "\n",
    "## Key Features Demonstrated\n",
    "\n",
    "‚úÖ **PostgreSQL Integration**: Direct connection with environment variables  \n",
    "‚úÖ **Cross-system Analytics**: PostgreSQL + S3 data federation with DuckDB  \n",
    "‚úÖ **Advanced Visualizations**: Multi-panel charts and analysis  \n",
    "‚úÖ **Real Analytics**: Customer segmentation, product performance, time series  \n",
    "\n",
    "Happy PostgreSQL analytics!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}