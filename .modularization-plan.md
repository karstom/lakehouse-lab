# Lakehouse Lab Modularization Plan

**Status**: In Progress  
**Started**: 2025-07-27  
**Last Updated**: 2025-07-27 18:47 UTC

## Objective
Break down the monolithic `init-all-in-one.sh` (2003 lines) into maintainable modules while preserving exact functionality and reliability.

## Design Principles
- **Preserve current working flow** exactly
- **Maintain strict sequential execution** (no parallelism to avoid timing issues)
- **Keep same external interface** (single script call)
- **Better debugging** through smaller, focused modules
- **Error propagation** - any failure stops everything
- **Template-based content** - no more heredocs/embedded code

## Target Directory Structure
```
lakehouse-lab/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â””â”€â”€ init-core.sh              # Shared utilities (~100 lines)
â”‚   â”œâ”€â”€ init-infrastructure.sh        # Directories, permissions, MinIO client (~150 lines)
â”‚   â”œâ”€â”€ init-storage.sh              # MinIO config, buckets (~200 lines)
â”‚   â”œâ”€â”€ init-compute.sh              # Iceberg JARs (~100 lines)
â”‚   â”œâ”€â”€ init-workflows.sh            # Airflow setup (copy DAGs) (~100 lines)
â”‚   â”œâ”€â”€ init-analytics.sh            # Jupyter setup (copy notebooks) (~150 lines)
â”‚   â””â”€â”€ init-dashboards.sh           # Homer, Superset (copy configs) (~150 lines)
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ airflow/
â”‚   â”‚   â””â”€â”€ dags/
â”‚   â”‚       â”œâ”€â”€ sample_duckdb_pipeline.py
â”‚   â”‚       â”œâ”€â”€ postgres_analytics_dag.py  
â”‚   â”‚       â”œâ”€â”€ data_quality_check.py
â”‚   â”‚       â””â”€â”€ postgres_streaming_dag.py
â”‚   â”œâ”€â”€ jupyter/
â”‚   â”‚   â””â”€â”€ notebooks/
â”‚   â”‚       â”œâ”€â”€ 01_Getting_Started.ipynb
â”‚   â”‚       â”œâ”€â”€ 02_PostgreSQL_Analytics.ipynb
â”‚   â”‚       â””â”€â”€ 03_Iceberg_Tables.ipynb
â”‚   â”œâ”€â”€ homer/
â”‚   â”‚   â””â”€â”€ config.yml
â”‚   â”œâ”€â”€ superset/
â”‚   â”‚   â””â”€â”€ database_setup.py
â”‚   â””â”€â”€ sample-data/
â”‚       â””â”€â”€ generate_orders.py
â””â”€â”€ init-all-in-one.sh               # Main orchestrator (~50 lines)
```

## Module Breakdown

### 1. scripts/lib/init-core.sh
**Purpose**: Shared utilities  
**Functions**:
- `log()`, `log_error()`, `log_success()`, `log_warning()`, `log_info()`
- `cleanup()`
- `wait_for_service()`, `wait_for_minio_api()`

### 2. scripts/init-infrastructure.sh
**Purpose**: Basic infrastructure setup  
**Functions**:
- `create_directories()`
- `set_permissions()`
- `install_minio_client()`

### 3. scripts/init-storage.sh
**Purpose**: Storage layer setup  
**Functions**:
- `configure_minio()`
- `create_buckets()`

### 4. scripts/init-compute.sh
**Purpose**: Compute layer setup  
**Functions**:
- `download_iceberg_jars()`

### 5. scripts/init-workflows.sh
**Purpose**: Workflow orchestration setup  
**Functions**:
- Copy DAGs from templates/airflow/dags/ to lakehouse-data/airflow/dags/
- Set proper permissions

### 6. scripts/init-analytics.sh
**Purpose**: Analytics environment setup  
**Functions**:
- Copy notebooks from templates/jupyter/notebooks/ to lakehouse-data/notebooks/
- Copy sample data generation script
- Execute sample data generation

### 7. scripts/init-dashboards.sh
**Purpose**: Dashboard and BI setup  
**Functions**:
- Copy Homer config from templates/
- Copy and execute Superset database setup script

### 8. init-all-in-one.sh (New Main)
**Purpose**: Orchestration  
**Structure**:
```bash
#!/bin/bash
set -e

# Source shared utilities
source "$(dirname "$0")/scripts/lib/init-core.sh"

# Set trap for cleanup
trap cleanup EXIT

log "Starting Lakehouse Lab initialization..."

# Execute modules in strict order
./scripts/init-infrastructure.sh
./scripts/init-storage.sh  
./scripts/init-compute.sh
./scripts/init-workflows.sh
./scripts/init-analytics.sh
./scripts/init-dashboards.sh

log_success "Lakehouse Lab initialization complete!"
```

## Template Files to Create

### Airflow DAGs
- `templates/airflow/dags/sample_duckdb_pipeline.py` - Extract from current heredoc
- `templates/airflow/dags/postgres_analytics_dag.py` - Extract from current heredoc
- `templates/airflow/dags/data_quality_check.py` - Extract from current heredoc
- `templates/airflow/dags/postgres_streaming_dag.py` - Extract from current heredoc

### Jupyter Notebooks
- `templates/jupyter/notebooks/01_Getting_Started.ipynb` - Extract from current Python string
- `templates/jupyter/notebooks/02_PostgreSQL_Analytics.ipynb` - Extract from current Python string
- `templates/jupyter/notebooks/03_Iceberg_Tables.ipynb` - Extract from current Python string

### Configuration Files
- `templates/homer/config.yml` - Extract from current heredoc
- `templates/superset/database_setup.py` - Extract from current Python script

### Sample Data
- `templates/sample-data/generate_orders.py` - Extract from current Python script

## Benefits of New Structure
- **Dramatic size reduction**: Scripts become 50-150 lines each instead of 2003
- **Proper syntax highlighting**: .py and .ipynb files get proper IDE support  
- **Easier editing**: No more escaping issues in heredocs
- **Better version control**: Clean diffs on content changes
- **Maintainable**: Edit notebooks as notebooks, not shell strings
- **Debuggable**: Isolated failure points
- **Testable**: Each module can be tested independently

## Implementation Progress

### âœ… Completed
- [x] Plan created and documented
- [x] Target structure defined
- [x] Extract template files from current script
  - [x] templates/airflow/dags/ (4 DAG files)
  - [x] templates/jupyter/notebooks/ (3 notebook files)  
  - [x] templates/sample-data/generate_orders.py
  - [x] templates/homer/config.yml
  - [x] templates/superset/database_setup.py
- [x] Create scripts/lib/init-core.sh (196 lines)
- [x] Create scripts/init-infrastructure.sh (172 lines)  
- [x] Create scripts/init-storage.sh (239 lines)
- [x] Create scripts/init-compute.sh (212 lines)
- [x] Create scripts/init-workflows.sh (206 lines)

### âœ… Implementation Complete!
- [x] Create scripts/init-analytics.sh (267 lines)
- [x] Create scripts/init-dashboards.sh (276 lines)  
- [x] Create new streamlined init-all-in-one-modular.sh (396 lines)

### ðŸš§ Ready for Testing
- [ ] Create scripts/init-storage.sh
- [ ] Create scripts/init-compute.sh
- [ ] Create scripts/init-workflows.sh
- [ ] Create scripts/init-analytics.sh
- [ ] Create scripts/init-dashboards.sh
- [ ] Create new streamlined init-all-in-one.sh
- [ ] Test modular execution
- [ ] Verify identical functionality

## Risk Mitigation
- **Backwards compatibility**: Same external interface maintained
- **Sequential execution**: No timing issues from parallelization
- **Error handling**: set -e ensures any failure stops the process
- **Testing approach**: Compare before/after lakehouse-data directory contents

## Success Criteria
1. **Functional parity**: Identical output in lakehouse-data/ directory
2. **Same reliability**: No new failure modes introduced  
3. **Maintainable code**: Each script <200 lines, focused responsibility
4. **Template approach**: All content as proper files with syntax highlighting